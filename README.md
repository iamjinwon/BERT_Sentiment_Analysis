# NSMC Sentiment Analysis with BERT

## 개요
이 저장소는 사전 학습된 BERT 모델을 활용하여 NSMC(네이버 영화 리뷰 댓글) 데이터셋으로 감성 분석(Sentiment Analysis)을 수행한 프로젝트입니다. 체계적인 전처리, 다양한 형태소 분석기 실험, 데이터 증강 기법을 통해 베이스라인 모델의 성능을 **0.9055**에서 **0.9095**로 향상시켰습니다. 이는 체계적인 전처리와 혁신적인 데이터 증강 전략이 모델 성능에 미치는 영향을 잘 보여줍니다.

---

## 주요 특징

### 1. **전처리 기법**
- **불용어 제거**: 의미가 적은 자주 등장하는 단어를 제거.
- **어간 추출(Stemming)**: 단어의 어형 변화를 원형으로 변환.
- **형태소 분석**: 다양한 한국어 형태소 분석기 성능 비교:
  - **Okt**
  - **Komoran**
  - **Bareun**

### 2. **데이터 증강**
- **문자 위치 변경**: 문장에서 문자의 위치를 랜덤하게 변경하여 데이터 다양성 증가.
- **랜덤 단어 삭제**: 단어를 랜덤하게 삭제하여 다양한 샘플 생성.
- **Back Translation**: GPT-3.5 Turbo를 사용하여 한글 리뷰를 영어로 번역한 후 다시 한글로 번역, 의미는 유지하면서 구문 변화를 도입.

### 3. **모델 학습**
- **사전 학습된 BERT 모델**을 활용하여 NSMC 데이터셋에 맞게 미세 조정(Fine-Tuning).
- 최적의 결과를 보장하기 위해 하이퍼파라미터 튜닝을 포함한 견고한 학습 파이프라인 구현.

---

## 결과

### 성능 지표
| 지표           | 베이스라인 (BERT) | 개선된 모델 |
|----------------|-------------------|-------------|
| 정확도(Accuracy) | 0.9055            | **0.9095**  |

미세 조정된 모델은 감성 분류 정확도가 향상되었으며, 이는 전처리 및 증강 기법의 효과를 입증합니다.

---

## 참고 자료
- **NSMC 데이터셋**: https://github.com/e9t/nsmc
- **BERT 사전 학습 모델**: Hugging Face Transformers
- **Back Translation**: GPT-3.5 Turbo 활용

